{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16fb9862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\seema\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\seema\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ca1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from xgboost import XGBClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59328238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the same rolling averages dataset\n",
    "full = pd.read_csv(\"../data/nba_games_rolling_averages.csv\", index_col=0)\n",
    "\n",
    "# 2. Remove non-numeric and target-related columns\n",
    "removed_columns = list(full.columns[full.dtypes == \"object\"]) + [\n",
    "    'season', 'date', 'won', 'target', 'team', 'team_opp'\n",
    "]\n",
    "selected_columns = full.columns[~full.columns.isin(removed_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aba12630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create an XGBoost model\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=120,       # number of boosting rounds (kept small for speed in SFS)\n",
    "    learning_rate=0.1,      # step size shrinkage; higher means faster convergence but slightly less precision\n",
    "    max_depth=3,            # max depth of each tree; shallower trees train faster and avoid overfitting small noise\n",
    "    min_child_weight=5,     # min sum of instance weights needed in a child; higher values = more conservative splits\n",
    "    subsample=0.8,          # % of training rows sampled for each tree; adds randomness for generalization\n",
    "    colsample_bytree=0.8,   # % of features sampled for each tree; also helps generalization\n",
    "    gamma=0,                # min loss reduction to make a split; 0 means allow all beneficial splits\n",
    "    reg_alpha=0.0,          # L1 regularization term; higher values encourage sparsity in weights\n",
    "    reg_lambda=1.0,         # L2 regularization term; higher values shrink weights to reduce overfitting\n",
    "    tree_method=\"hist\",     # histogram-based tree growth; much faster than exact on CPU\n",
    "    n_jobs=4,               # number of parallel threads to use for training\n",
    "    random_state=42,        # random seed for reproducibility\n",
    "    eval_metric=\"logloss\"   # evaluation metric; log loss is standard for binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2046e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Time series split for feature selection\n",
    "split = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# 5. Sequential feature selection with XGBoost\n",
    "sfs = SequentialFeatureSelector(\n",
    "    xgb,\n",
    "    n_features_to_select=30,\n",
    "    direction=\"forward\",\n",
    "    cv=split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71dc036d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                          estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                                  callbacks=None,\n",
       "                                                  colsample_bylevel=None,\n",
       "                                                  colsample_bynode=None,\n",
       "                                                  colsample_bytree=0.8,\n",
       "                                                  device=None,\n",
       "                                                  early_stopping_rounds=None,\n",
       "                                                  enable_categorical=False,\n",
       "                                                  eval_metric='logloss',\n",
       "                                                  feature_types=None, gamma=0,\n",
       "                                                  grow_...one,\n",
       "                                                  importance_type=None,\n",
       "                                                  interaction_constraints=None,\n",
       "                                                  learning_rate=0.1,\n",
       "                                                  max_bin=None,\n",
       "                                                  max_cat_threshold=None,\n",
       "                                                  max_cat_to_onehot=None,\n",
       "                                                  max_delta_step=None,\n",
       "                                                  max_depth=3, max_leaves=None,\n",
       "                                                  min_child_weight=5,\n",
       "                                                  missing=nan,\n",
       "                                                  monotone_constraints=None,\n",
       "                                                  multi_strategy=None,\n",
       "                                                  n_estimators=120, n_jobs=4,\n",
       "                                                  num_parallel_tree=None,\n",
       "                                                  random_state=42, ...),\n",
       "                          n_features_to_select=30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.fit(full[selected_columns], full[\"target\"])\n",
    "# 6. Save the model and selected features using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac6a3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/xg_boost/model_xgb.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(sfs, '../models/xg_boost/feature_selector_xgb.pkl')\n",
    "joblib.dump(xgb, '../models/xg_boost/model_xgb.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
