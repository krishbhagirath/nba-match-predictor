{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d20552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "sfs = joblib.load('../models/xg_boost/feature_selector_xgb.pkl') # load the new feature selector from file for future use\n",
    "xgb  = joblib.load('../models/xg_boost/model_xgb.pkl') # load the new model from file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95051157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the same rolling averages dataset\n",
    "full = pd.read_csv(\"../data/nba_games_rolling_averages.csv\", index_col=0)\n",
    "\n",
    "# 2. Remove non-numeric and target-related columns\n",
    "removed_columns = list(full.columns[full.dtypes == \"object\"]) + [\n",
    "    'season', 'date', 'won', 'target', 'team', 'team_opp'\n",
    "]\n",
    "selected_columns = full.columns[~full.columns.isin(removed_columns)]\n",
    "predictors = list(selected_columns[sfs.get_support()]) # get the selected features from the feature selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef06be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data, model, predictors, start=2, step=1):\n",
    "    # since we have time series data, we cannot split data up with usual cross-validation (must use historical data to predict future outcomes)\n",
    "    # function will split data into season, use past seasons to predict future seasons\n",
    "\n",
    "    # start = 2: 2 seasons min to start predicting (ex: using 2016/2017 to predict 2018)\n",
    "\n",
    "    all_predictions = [] # list of dataframes for predictions of one season\n",
    "\n",
    "    seasons = sorted(data[\"season\"].unique()) # sort data by season\n",
    "\n",
    "    for i in range(start, len(seasons), step):\n",
    "        season = seasons[i] # each loop iteration is a new season\n",
    "        train = data[data[\"season\"] < season] # training data is ALL DATA BEFORE CURRENT SEASON\n",
    "        test = data[data[\"season\"] == season] # current season is tested/predicted\n",
    "\n",
    "        model.fit(train[predictors], train[\"target\"]) # calls model to find combinations in training data that give us most accuracy to target\n",
    "\n",
    "        preds = model.predict(test[predictors]) # allow model to make predictions on DIFFERENT DATA than training data\n",
    "        # predictions made using training data will yield unrealistically high accuracy as expected\n",
    "\n",
    "        preds = pd.Series (preds, index=test.index) #convert predictions to Series with same index as test data\n",
    "\n",
    "        combined = pd.concat( [test[\"target\"], preds], axis=1) # combine predictions and real outcomes into one dataframe/table\n",
    "        combined.columns = [\"actual\", \"prediction\"] # rename columns\n",
    "\n",
    "        all_predictions.append(combined) # add predictions to list of predictions\n",
    "    \n",
    "    return pd.concat(all_predictions) #combine all seasons into one dataframe at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8ef27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = backtest(full, xgb, predictors) # run backtest function with new data, model, and predictors (metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1d338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6317923763179237"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predictions[\"actual\"], predictions[\"prediction\"]) # accuracy of prediction (compare actual to predictions)\n",
    "\n",
    "\n",
    "# 63.1% accuracy with a lightweight XGBoost model - slight DECLINE from Ridge Regression (64%)\n",
    "# greater number of trees (n-predictors) likely would have performed better\n",
    "# however, the model's complexity and training time would also increase\n",
    "# ex: my 500 n-predictor model ran 10 hours without finishing\n",
    "# trade-off: accuracy vs. training time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
